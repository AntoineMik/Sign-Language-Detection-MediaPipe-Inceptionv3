# Sign-Language-Detection-MediaPipe-Inceptionv3

## Introduction

The ability of a system to perceive and detect sign language is a vital component of improving accessibility across a variety of technological domains and platforms. For example, it can understand sign language and hand gestures and overlay the translation on top of the physical world in augmented or virtual reality. The real-time hand gesture perception has been solved by Google's MediaPipe and open-source, cross-platform framework for building pipelines to process data of different natures such as video and audio. The MediaPipe hand landmarks detection approach allows us to detect the position of individual fingers, making it ideal for building a machine learning model to identify sign language numbers and alphabet.

## Goal

#### Technical concepts

Computer Vision, 
TensorFlow,
Keras,
MediaPipe,
InceptionV3, 
Convolutional Neural Network (CNN)


https://antoinemik.github.io/Sign-Language-Detection-MediaPipe-Inceptionv3/